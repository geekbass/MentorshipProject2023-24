{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6452076-0fbd-4daa-a8f3-358fe600f06f",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "We are going to train a sentiment analysis Model to determine if a Yelp review is either Positive Or Negative.\n",
    "\n",
    "This model training session is also going to be used as a case study to see how accurate the XGBoost Framework can be used in this type of scenario. This is typically not an NLP framework used.\n",
    "\n",
    "This session will teach the importance of Preprocessing data as well as how to train a model. We will use the popular nltk project for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72715269-fd11-416c-b973-0d6d4f2acd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional libraries\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e562a78-5bec-4da0-b1ad-169d29d94261",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RESTART KERNEL FoR NEW LIBRARY TO TAKE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a252da9a-6ca0-4013-a4a2-df8e0b84b511",
   "metadata": {},
   "source": [
    "# Preparing our Data\n",
    "We just created a dataset and saved it as 'training_data.csv' in Session 2. We are going to use this to train our model. We will need to clean up and preprocess our data. We will use nltk for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e5e75a2-e0e8-4be4-a525-601349d88728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3</td>\n",
       "      <td>First visit...Had lunch here today - used my G...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>4</td>\n",
       "      <td>Should be called house of deliciousness!\\n\\nI ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4</td>\n",
       "      <td>I recently visited Olive and Ivy for business ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2</td>\n",
       "      <td>My nephew just moved to Scottsdale recently so...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>5</td>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stars                                               text sentiment\n",
       "0         5  My wife took me here on my birthday for breakf...  positive\n",
       "1         5  I have no idea why some people give bad review...  positive\n",
       "2         4  love the gyro plate. Rice is so good and I als...  positive\n",
       "3         5  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  positive\n",
       "4         5  General Manager Scott Petello is a good egg!!!...  positive\n",
       "...     ...                                                ...       ...\n",
       "9995      3  First visit...Had lunch here today - used my G...  positive\n",
       "9996      4  Should be called house of deliciousness!\\n\\nI ...  positive\n",
       "9997      4  I recently visited Olive and Ivy for business ...  positive\n",
       "9998      2  My nephew just moved to Scottsdale recently so...  negative\n",
       "9999      5  4-5 locations.. all 4.5 star average.. I think...  positive\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dataset to Pandas DF\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('training_data.csv', index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd0e761-771f-483d-9338-4d016588dbf0",
   "metadata": {},
   "source": [
    "# Preprocess with nltk\n",
    "We will use stopwords and WordNetLemmatizer.\n",
    "\n",
    "**Stop words** - Stop words are a set of commonly used words in a language. Examples of stop words in English are “a,” “the,” “is,” “are,” etc. Stop words are commonly used in Text Mining and Natural Language Processing (NLP) to eliminate words that are so widely used that they carry very little useful information.\n",
    "\n",
    "**Word Lemmatizer** - Reduce a word to its root form, also called a lemma. For example, the verb \"running\" would be identified as \"run.\" Lemmatization studies the morphological, or structural, and contextual analysis of words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2cd5ba-f9ee-4d98-9017-ef7b9c621af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/weston/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/weston/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# Download corpora (shit ton of text)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# English stop words here\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a9a01d9-ccc2-4dca-a06d-44d56aaa9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that cleans up the text. Remove things like punctuation, convert to lowercase, lemmatize and remove stop words\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text, re.UNICODE)\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Lemmatize\n",
    "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")] \n",
    "    # remove stop words\n",
    "    text = [word for word in text if not word in stop_words] \n",
    "    # Bring the list back into a string\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7e94b8c-bad9-4fa2-8b0f-4fe7a78a7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text cleaning function above to each row (lambda) of our dataset \n",
    "# Here we add an additional row just to demonstrate.\n",
    "# This is the column we will train our model on!\n",
    "data['cleaned_text'] = data.text.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf524395-4918-4412-9c82-2382b10cb805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wife took birthday breakfast wa excellent  wea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>positive</td>\n",
       "      <td>idea people give bad review place go show plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>positive</td>\n",
       "      <td>love gyro plate rice good also dig candy selec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>positive</td>\n",
       "      <td>rosie dakota love chaparral dog park convenien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>positive</td>\n",
       "      <td>general manager scott petello good egg go deta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3</td>\n",
       "      <td>First visit...Had lunch here today - used my G...</td>\n",
       "      <td>positive</td>\n",
       "      <td>first visithad lunch today  used groupon  \\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>4</td>\n",
       "      <td>Should be called house of deliciousness!\\n\\nI ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>called house deliciousness\\n\\ni could go item ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4</td>\n",
       "      <td>I recently visited Olive and Ivy for business ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>recently visited olive ivy business last week ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2</td>\n",
       "      <td>My nephew just moved to Scottsdale recently so...</td>\n",
       "      <td>negative</td>\n",
       "      <td>nephew moved scottsdale recently bunch friend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>5</td>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>positive</td>\n",
       "      <td>45 location 45 star average think arizona real...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stars                                               text sentiment  \\\n",
       "0         5  My wife took me here on my birthday for breakf...  positive   \n",
       "1         5  I have no idea why some people give bad review...  positive   \n",
       "2         4  love the gyro plate. Rice is so good and I als...  positive   \n",
       "3         5  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  positive   \n",
       "4         5  General Manager Scott Petello is a good egg!!!...  positive   \n",
       "...     ...                                                ...       ...   \n",
       "9995      3  First visit...Had lunch here today - used my G...  positive   \n",
       "9996      4  Should be called house of deliciousness!\\n\\nI ...  positive   \n",
       "9997      4  I recently visited Olive and Ivy for business ...  positive   \n",
       "9998      2  My nephew just moved to Scottsdale recently so...  negative   \n",
       "9999      5  4-5 locations.. all 4.5 star average.. I think...  positive   \n",
       "\n",
       "                                           cleaned_text  \n",
       "0     wife took birthday breakfast wa excellent  wea...  \n",
       "1     idea people give bad review place go show plea...  \n",
       "2     love gyro plate rice good also dig candy selec...  \n",
       "3     rosie dakota love chaparral dog park convenien...  \n",
       "4     general manager scott petello good egg go deta...  \n",
       "...                                                 ...  \n",
       "9995  first visithad lunch today  used groupon  \\n\\n...  \n",
       "9996  called house deliciousness\\n\\ni could go item ...  \n",
       "9997  recently visited olive ivy business last week ...  \n",
       "9998  nephew moved scottsdale recently bunch friend ...  \n",
       "9999  45 location 45 star average think arizona real...  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read it an notice the differences between text and cleaned_text columns\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a02238-5eb6-47fe-9a01-f3ff3978ee5a",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "In natural language processing (NLP), feature extraction is a fundamental task that involves converting raw text data into a format that can be easily processed by machine learning algorithms.\n",
    "\n",
    "Machines need read numerical data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1707e767-a729-434a-a152-b7c8771369b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Sklearn feature extractor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "\n",
    "# Vectorize (convert to numbers) on the cleaned_text column and make it an array to pass to our model for training\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfid_obj = vectorizer.fit_transform(data['cleaned_text'])\n",
    "\n",
    "# Save our fitted vectorizer using pickle\n",
    "vec_file = 'vectorizer.pickle'\n",
    "pickle.dump(vectorizer, open(vec_file, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ac7e13-0c87-4e29-b888-04180c509956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the features to an array and Read the array just to see\n",
    "data_features = tfid_obj.toarray()\n",
    "data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b604451e-25d4-4346-ac1e-b6697561be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need to make our sentiments a numerical value. To keep this simple we will make positive a 1 and negative a 0.\n",
    "def encode_sentiment(sentiment):\n",
    "    if sentiment == 'positive':\n",
    "        sentiment_value = 1\n",
    "    else:\n",
    "        sentiment_value = 0\n",
    "\n",
    "    return int(sentiment_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47103f3d-0fec-48d6-ba7f-b6bb53a9b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column with encodings \n",
    "data['encoded_sentiment'] = data.sentiment.apply(lambda x: encode_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60fb2b17-284c-4909-be47-4ec45a9e94bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>encoded_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wife took birthday breakfast wa excellent  wea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>positive</td>\n",
       "      <td>idea people give bad review place go show plea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>positive</td>\n",
       "      <td>love gyro plate rice good also dig candy selec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>positive</td>\n",
       "      <td>rosie dakota love chaparral dog park convenien...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>positive</td>\n",
       "      <td>general manager scott petello good egg go deta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3</td>\n",
       "      <td>First visit...Had lunch here today - used my G...</td>\n",
       "      <td>positive</td>\n",
       "      <td>first visithad lunch today  used groupon  \\n\\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>4</td>\n",
       "      <td>Should be called house of deliciousness!\\n\\nI ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>called house deliciousness\\n\\ni could go item ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4</td>\n",
       "      <td>I recently visited Olive and Ivy for business ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>recently visited olive ivy business last week ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2</td>\n",
       "      <td>My nephew just moved to Scottsdale recently so...</td>\n",
       "      <td>negative</td>\n",
       "      <td>nephew moved scottsdale recently bunch friend ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>5</td>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>positive</td>\n",
       "      <td>45 location 45 star average think arizona real...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stars                                               text sentiment  \\\n",
       "0         5  My wife took me here on my birthday for breakf...  positive   \n",
       "1         5  I have no idea why some people give bad review...  positive   \n",
       "2         4  love the gyro plate. Rice is so good and I als...  positive   \n",
       "3         5  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  positive   \n",
       "4         5  General Manager Scott Petello is a good egg!!!...  positive   \n",
       "...     ...                                                ...       ...   \n",
       "9995      3  First visit...Had lunch here today - used my G...  positive   \n",
       "9996      4  Should be called house of deliciousness!\\n\\nI ...  positive   \n",
       "9997      4  I recently visited Olive and Ivy for business ...  positive   \n",
       "9998      2  My nephew just moved to Scottsdale recently so...  negative   \n",
       "9999      5  4-5 locations.. all 4.5 star average.. I think...  positive   \n",
       "\n",
       "                                           cleaned_text  encoded_sentiment  \n",
       "0     wife took birthday breakfast wa excellent  wea...                  1  \n",
       "1     idea people give bad review place go show plea...                  1  \n",
       "2     love gyro plate rice good also dig candy selec...                  1  \n",
       "3     rosie dakota love chaparral dog park convenien...                  1  \n",
       "4     general manager scott petello good egg go deta...                  1  \n",
       "...                                                 ...                ...  \n",
       "9995  first visithad lunch today  used groupon  \\n\\n...                  1  \n",
       "9996  called house deliciousness\\n\\ni could go item ...                  1  \n",
       "9997  recently visited olive ivy business last week ...                  1  \n",
       "9998  nephew moved scottsdale recently bunch friend ...                  0  \n",
       "9999  45 location 45 star average think arizona real...                  1  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at dataset\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014dfeac-5bf2-4c91-9559-0e45a4c99630",
   "metadata": {},
   "source": [
    "# Split the data\n",
    "The train-validation-test split is a strategy that divides a dataset into three essential subsets: the training set, the validation set, and the test set. Each subset serves a distinct purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c408a1d5-a241-48db-bb16-f741dbb2af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test will be our array above\n",
    "# y_train, y_test is our encoded_sentiment. y is the result (prediction_ you are going for)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_features, data['encoded_sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "395471a4-7e8f-41fe-aa98-d51d9be7cefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.50226399, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " 9254    1\n",
       " 1561    1\n",
       " 1670    1\n",
       " 6087    1\n",
       " 6669    1\n",
       "        ..\n",
       " 5734    1\n",
       " 5191    1\n",
       " 5390    1\n",
       " 860     1\n",
       " 7270    1\n",
       " Name: encoded_sentiment, Length: 8000, dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ed5b02-437c-4b69-8ad2-8fec27c72810",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "Now the fun part!!!! Train an model!!!\n",
    "\n",
    "Now we are going to train an XGBoost model our our training data (X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48a91530-7a21-4d5f-ba86-7dec7dd5a421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Use the Classifier. We can adjust the parameters here to try to get better results.\n",
    "model = xgb.XGBClassifier(max_depth=10, n_estimators=1000, learning_rate=0.01)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "044b17aa-aa67-4dc0-8f40-fc8695144974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our model locally\n",
    "model.save_model(\"model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65318f82-564d-4c7a-a977-6430832dec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can do model evaluations using our Test Dataset\n",
    "# Use the model to run predictions across 2000K rows\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39536f1a-d7a8-4e01-b518-4dacf5a9133a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will output the encoded sentiments\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9315aac-5255-4aab-91b4-f10d8f4d1c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are several ways we can see the results with different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ff4c392-f31b-4fc4-9b3d-a69ce09ff576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.36      0.50       308\n",
      "           1       0.89      0.99      0.94      1692\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.86      0.67      0.72      2000\n",
      "weighted avg       0.88      0.89      0.87      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5706d75-de90-4436-883f-340c4568a92c",
   "metadata": {},
   "source": [
    "# Inference (Real Tests)\n",
    "Now lets run through the process of using some real text to get predictions. We must follow the same steps we did for training as we do to get results.\n",
    "\n",
    "**Inference** - Applying a machine learning model to a dataset and generating an output or “prediction”. This output might be a numerical score, a string of text, an image, or any other structured or unstructured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb03dd-c3d7-436e-9b52-1447a7f0c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model if needed\n",
    "# import xgboost as xgb\n",
    "\n",
    "# model = xgb.XGBClassifier(max_depth=10, n_estimators=1000, learning_rate=0.01)\n",
    "# model.load_model(\"model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1543c4b-f681-46d6-8361-572865d1f90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/weston/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/weston/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Follow same steps as dataprocessing for model\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# Download corpora (shit ton of text)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# English stop words here\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20d7d4f2-b650-403a-a7d4-bc797daf8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our vectorizer\n",
    "loaded_vectorizer = pickle.load(open('vectorizer.pickle', 'rb'))\n",
    "\n",
    "def clean_and_vectorize(text):\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text, re.UNICODE)\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Lemmatize\n",
    "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")] \n",
    "    # remove stop words\n",
    "    text = [word for word in text if not word in stop_words] \n",
    "    # Bring the list back into a string\n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Vectorize from our vectorizer created above\n",
    "    data_features = loaded_vectorizer.transform([text])\n",
    "    # Create an array as it expects\n",
    "    data_features = data_features.toarray()\n",
    "\n",
    "    # Get the prediciton \n",
    "    prediction = model.predict(data_features)[0]\n",
    "\n",
    "    # 1 is positive 0 is negative\n",
    "    if prediction == 1:\n",
    "        sentiment = 'positive'\n",
    "    else: \n",
    "        sentiment = 'negative'\n",
    "\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4f87dd1-8a13-4eab-9c2b-b67f787f5b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'This place is the greatest on earth!'\n",
    "prediction = clean_and_vectorize(text)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d08174e-453f-418c-b9ff-9d89ebfcc86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Alqueria surpassed my expectations ten fold. You can tell that their food is authentic farm-to-table and is just incredibly fresh.\n",
    "We ordered the shrimp and drunken goat cheese as our appetizers and they proved we made the right decision in choosing Alqueria for dinner. The shrimp, with the oil that it is in, is unrivaled. I would come back just to eat more of this! The lamb and spaghetti squash were also very good. The lamb fell right off the bone.\n",
    "Our server was very sweet to us, offered her suggestions, and always checked in.\n",
    "I do love the intimate feel of the restaurant, however, reservations are necessary since it is a smaller place.\n",
    "The menu changes often which I think is a fun concept, but I am really hoping they don't ever take the shrimp off the menu!\n",
    "Braised Lamb Shank & Local Spaghetti Squash\n",
    "\"\"\"\n",
    "\n",
    "prediction = clean_and_vectorize(text)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9b88ac5-945b-48ca-91cf-e04d8ac37af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Wow! Downright awful! Some background: I have avoided eating Panera basically my entire life because it's terrible. However! In Orlando a group of friends wanted to go to Panera, so I went. It was awesome! So good that I told several people about it and was like we have to go when we're all back in Columbus because it was so good. Which was so surprising. Well. Here we are. And it was awful. Terrible. Put together terribly and tasted like feet and rot. Stay away. Better to not eat than to waste money on this garbage.\n",
    "\"\"\"\n",
    "prediction = clean_and_vectorize(text)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d191aa1e-4a3e-4d3b-8050-ed6aede32738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
